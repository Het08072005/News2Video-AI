# -*- coding: utf-8 -*-
"""text_to_video_news_project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QWYBBVoIeuHWjarWytTf_I8UXkESHuEK
"""

!pip install -q torch diffusers transformers accelerate gTTS pydub opencv-python-headless numpy
!apt-get -y install ffmpeg

import os
import re
from diffusers import DiffusionPipeline
import torch
from gtts import gTTS
from pydub import AudioSegment
import cv2
from IPython.display import HTML
from base64 import b64encode
import subprocess # Added subprocess import

os.makedirs("/content/images", exist_ok=True)
os.makedirs("/content/audio", exist_ok=True)

# Step 3: Input text

news_text = """
President Donald Trump announced the U.S. has seized an oil tanker off the coast of Venezuela.
Venezuela condemned the action, calling it an act of aggression.
International tensions are rising worldwide.
"""

# Step 4: Split text into sentences (regex-based)

def split_sentences(text):
    sentences = re.split(r'(?<=[.!?])\s+', text.strip())
    return [s for s in sentences if s]

sentences = split_sentences(news_text)
print("Sentences:", sentences)

# Step 5: Load Diffusers model
device = "cuda" if torch.cuda.is_available() else "cpu"
pipe = DiffusionPipeline.from_pretrained(
    "common-canvas/CommonCanvas-S-NC",
    dtype=torch.float16,
    device_map=device # Changed "auto" to "cuda" as per error message
)

# Step 6: Generate images and audio

image_paths = []
audio_paths = []

for i, sent in enumerate(sentences):
    print(f"Processing sentence {i+1}/{len(sentences)}...")

    # Generate image
    img = pipe(sent).images[0]
    img_path = f"/content/images/image_{i}.png"
    img.save(img_path)
    image_paths.append(img_path)

    # Generate audio
    tts = gTTS(sent)
    aud_path = f"/content/audio/audio_{i}.mp3"
    tts.save(aud_path)
    audio_paths.append(aud_path)

# Step 7: Create video using OpenCV

frame_size = (640, 480)
fps = 1  # repeat frames according to audio length
video_name = "/content/final_news_video.avi"
fourcc = cv2.VideoWriter_fourcc(*"XVID")
out = cv2.VideoWriter(video_name, fourcc, fps, frame_size)

for img_path, aud_path in zip(image_paths, audio_paths):
    img = cv2.imread(img_path)
    img = cv2.resize(img, frame_size)

    audio = AudioSegment.from_mp3(aud_path)
    duration_sec = int(audio.duration_seconds)
    duration_sec = max(duration_sec, 1)

    for _ in range(duration_sec):
        out.write(img)

out.release()

# Step 8: Merge audio using pydub + ffmpeg

combined_audio = AudioSegment.empty()
for aud_path in audio_paths:
    combined_audio += AudioSegment.from_mp3(aud_path)
combined_audio.export("/content/final_audio.wav", format="wav")

# Merge video + audio
subprocess.call(
    'ffmpeg -y -i /content/final_news_video.avi -i /content/final_audio.wav -c:v copy -c:a aac /content/final_news_video.mp4',
    shell=True
)

# Step 9: Display video in Colab

mp4 = open("/content/final_news_video.mp4",'rb').read()
data_url = "data:video/mp4;base64," + b64encode(mp4).decode()
HTML(f"""
<video width=640 controls>
      <source src="{data_url}" type="video/mp4">
</video>
""")



